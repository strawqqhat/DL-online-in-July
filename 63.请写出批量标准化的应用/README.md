批量归一化中，norm是数据标准化或归一化，batch可以理解为批量，加起来就是批量标准化。解决在训练过程中中间层数数据分布发生改变的问题，以防止梯度消失或爆炸，加快训练速度。

* 神经网络学习过程的本质就是学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的泛化能力大大降低，所以需要使用输入数据归一化方法，使训练数据与测试数据的分布相同。
* 另一方面，神经网络训练时一旦某一层的输入数据分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。